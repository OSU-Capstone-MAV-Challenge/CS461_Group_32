\documentclass[onecolumn, draftclsnofoot,10pt, compsoc]{IEEEtran}
\usepackage{url}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{epstopdf}
\epstopdfsetup{update} % only regenerate pdf files when eps file is newer
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{indentfirst}
\usepackage{geometry}
\usepackage{color}
\usepackage{tikz}
\usepackage{rotating}
\usepackage{pgfgantt}
\usepackage{xcolor}
\geometry{textheight=9.5in, textwidth=7in}


% 1. Fill in these details
\def \CapstoneTeamName{		MAV Challenge}
\def \CapstoneTeamNumber{		32}
\def \GroupMemberOne{			Justin Sherburne}
\def \GroupMemberTwo{			Kaiyuan Fan}
\def \GroupMemberThree{			Yingshi Huang}
\def \CapstoneProjectName{		AHS Micro-Air Vehicle Challenge}
%\def \CapstoneSponsorCompany{	Columbia Helicopters}
\def \CapstoneSponsorPerson{		Nancy Squires, Ph.D.}

% 2. Uncomment the appropriate line below so that the document type works
\def \DocType{		%Problem Statement
				%Requirements Document
				%Technology Review
				%Design Document
				Midterm Report
				}
			
\newcommand{\NameSigPair}[1]{\par
\makebox[2.75in][r]{#1} \hfil 	\makebox[3.25in]{\makebox[2.25in]{\hrulefill} \hfill		\makebox[.75in]{\hrulefill}}
\par\vspace{-12pt} \textit{\tiny\noindent
\makebox[2.75in]{} \hfil		\makebox[3.25in]{\makebox[2.25in][r]{Signature} \hfill	\makebox[.75in][r]{Date}}}}
% 3. If the document is not to be signed, uncomment the RENEWcommand below
\renewcommand{\NameSigPair}[1]{#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\begin{titlepage}
    \pagenumbering{gobble}
    \begin{singlespace}
    	\includegraphics[height=4cm]{coe_v_spot1}
        \hfill 
        % 4. If you have a logo, use this includegraphics command to put it on the coversheet.
        %\includegraphics[height=4cm]{CompanyLogo}   
        \par\vspace{.2in}
        \centering
        \scshape{
            \huge CS Capstone \DocType \par
            {\large\today}\par
            \vspace{8pt}
            \textbf{\Huge\CapstoneProjectName}\par
			\vspace{1.5in}
            {\large Prepared for}\par
            % \Huge \CapstoneSponsorCompany\par
            % \vspace{5pt}
            {\Large\NameSigPair{\CapstoneSponsorPerson}\par}
			\vspace{3pt}
            {\large Prepared by }\par
            Group\CapstoneTeamNumber\par
            % 5. comment out the line below this one if you do not wish to name your team
            \CapstoneTeamName\par 
            \vspace{8pt}
            {\Large
                \NameSigPair{\GroupMemberOne}\par
                \NameSigPair{\GroupMemberTwo}\par
                \NameSigPair{\GroupMemberThree}\par
            }
            \vspace{.5in}
        }
        \begin{abstract}
        The purpose of this document is to provide a reflection on the progress of the Micro Air Vehicle project. We are now sixteen weeks into the project, approximately half of the way to completion. Here we will outline problems and possible solutions we have encountered this far, as well as a breakdown of weekly progress made thus far. 
        \end{abstract}     
    \end{singlespace}
\end{titlepage}
\newpage
\pagenumbering{arabic}
\tableofcontents
% 7. uncomment this (if applicable). Consider adding a page break.
%\listoffigures
%\listoftables
\clearpage


\section*{Revision History}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
		Name & Date & Reason For Changes & Version\\
        \hline
		Midterm Progress Report & Feb 15, 2018 & Initial Creation & 1.0\\
		\hline 
    \end{tabular}
\end{center}




\section{Purpose}

The purpose of this project is to design a vehicle capable of competing in the American Helicopter Society’s Micro-Air Vehicle challenge. We have elected to compete in the autonomous category, meaning our vehicle must be able to fly without any user interaction. We are representing Oregon State University for the first time at this competition, and if our project is successful we could gain additional outside funding similar to the OSU rocketry and solar teams.

\section{Project Goals}
The goal is to create a vehicle capable of navigating the competition environment without human control. Additionally, the vehicle should be able to pick up letters and deliver them to other locations within the competition environment. There are additional constraints on the size, weight, and specific functionalities of the vehicle, but from the computer science standpoint our goals are:

\begin{enumerate}
\item{The vehicle must be able to stream one camera feed to the base station for manual control. }
\item{We must have an emergency cut-off switch in case of a loss of communication or control. }
\item{We must have a manual override that will shut-down autonomous controls.}
\item{Ultrasonic sensors will be used to calculate distance from objects within the competition area in conjunction with the camera.}
\item{Image processing at minimum should be able to identify three objects: The letter, the landing area, and the boundary lines.}
\item{Any flight changes should originate from the base station, and motor controls should be implemented on the vehicle.}
\item{Our vehicle should fully comply with AHS competition rules and guidelines. }
\end{enumerate}

\section{Justin Sherburne's Report}

\subsection{Current Progress}

During the course of this term I have been developing our image recognition software for the competition. Currently I have implemented tracking based on object color. This should be sufficient for our autonomous design because the boundary is marked yellow, deliveries are red, and landing areas are black. It is possible to implement some form of pattern matching to fill in the gaps if the color is not enough by itself. Currently I am exploring an open-source guide written by Kyle Hounslow which fully implements object tracking based on color. Using this guide, we are able to identify individual colors in near real-time by filtering specific values from the video feed. Once these objects are tracked, their locations within the image frame are stored in a matrix. This matric is easily addressable and can be used by another function to predict where the aircraft should travel next. Because we had to remove one camera from our original design, the current plan for the autonomous flight will be to follow the boundary lines until we find one of our targets. 

Due to the complexity of the calculations being used for image processing, the majority of the processing is being done on the base station. Ultimately the code will also contain the controls feature and open a wireless link to the vehicle for control. It should require one parameter to be passed in at startup which is the IP of the vehicle (unless this IP can be fixed in the closed network). Streaming of the video occurs over the Wi-Fi Pineapple, which acts as a simple router for our purposes. This has been tested and works well in a variety of conditions. We will need to continue testing on the router in the future to make sure it can withstand long-distances and areas with strong network activity.


\subsection{Future Goals}

In the future I will continue to work on the image recognition side of the project and assist my teammates with their software when necessary. While I currently only have one color being filtered and targeted, I should be able to have several objects being tracked simultaneously by the end of the week. After that happens I will need to conduct some testing to see if we will also need to implement any pattern matching, or if we can move forward with just that. After the targets are identified, their location within the camera frame is stored in a matrix. This can be used very easily for logic controls and movement. 

The ultrasonic sensors will also need to be implemented on our design. We have not yet decided if that information will be relayed to the base station for calculations, or if it will remain on the PI zero controller. If it is local, we can use that information in real-time to avoid obstacles and track our height from the ground. Because the sensors have not yet been tested or installed on the aircraft we do not know what the distance measurements will be, or how that information will be best used.

\subsection{Problems}

One of the biggest problems I've encountered was in regard to the camera multiplexor we were planning on implementing. The documentation from the manufacturer wasn't completely correct, so it was not able to stream both camera’s at the same time. Instead you could only switch between the two feeds using the GPIO pins on the PI zero. Unfortunately for our situation if both cameras were not running simultaneously, then one of them was simply dead weight.

The second problem we've been experiencing has been from the ME and EE teams. Currently we are one month away from needing an alpha-level prototype for the competition. This means it is able to be flown, controlled manually, and have some autonomous implementation. The problem is that the ME and EE teams are still working on getting things implemented on the aircraft. The motors have not yet been wired to our motor controllers or attached to the PI Zero on-board. The ME team is still working on slight modifications to stability and balance, and the EE team needs to install voltage regulators and control modules. The CS team will have roughly two weeks to implement their progress on the aircraft before we need to demo for the competition.  

\subsection{Solutions}

Our solution to the camera problem had a couple of different options. The first option was to mount a second PI Zero to the vehicle. This is possible given our excess of thrust, but we would have also ran into issues with power and control. It is simple to have all of the components running to one PI Zero, but having two on the aircraft would unnecessarily complicate things. 

The second option, and the option we decided to take, was to lose a camera. This reduces the amount of information we are able to receive from the vehicle, but it also reduces the amount of network traffic and complexity of the project. In return we will need to rely more on our ultrasonic sensors and be a little more clever with our autonomous controls. The remaining camera will be directed straight down, and the aircraft will mostly trace the outside boundary, conducting a search pattern in the designated area.

The solution to the delay in hardware has been to do as much programming beforehand as possible. While we cannot yet build motor controls, we are able to press on with the image recognition and network communication portions. While some things are more challenging to implement without the physical device, many things can continue development without hardware. The CS team should have at least two weeks to implement as much functionality before we need to demo our aircraft for the competition.




\section{Yingshi Huang's Report}





\section{Kaiyuan Fan's Report}






\end{document}
